{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Based off of the 'CNN Image Classifier' tutorial by Nicholas Renotte\n",
    "Tutorial Video Link: 'https://www.youtube.com/watch?v=jztwpsIzEGc'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1684061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Dependencies\n",
    "#!pip3 install matplotlib\n",
    "#!pip3 install opencv-python\n",
    "#!pip3 install tensorflow\n",
    "#!pip3 install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903bba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Available Pip Libraries\n",
    "#!pip3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4df918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Dodgy Images\n",
    "image_data_directory = '../../Data/ImageRecognition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ede3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_image_extensions = ['bmp','jpeg', 'jpg', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a2bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(image_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b79b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(image_data_directory, 'Boats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c654a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(image_data_directory):\n",
    "    for image in os.listdir(os.path.join(image_data_directory, image_class)):\n",
    "        image_path = os.path.join(image_data_directory, image_class, image)\n",
    "        try:\n",
    "            current_image = cv2.imread(image_path)\n",
    "            current_image_extension = imghdr.what(image_path)\n",
    "            if(current_image_extension not in valid_image_extensions):\n",
    "                print('This image has an extension of {} which s invalid and not included within the current valid headers.'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as exception:\n",
    "            print('Issue with image {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying an example sample test image\n",
    "test_image = cv2.imread(os.path.join(image_data_directory, 'Boats', 'TS_Harbor_Sunrise.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2859c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading In Data\n",
    "image_dataset = tf.keras.utils.image_dataset_from_directory(image_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596788cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset_iterator = image_dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450dff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dec68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrives a batch of images as data from the iterator\n",
    "batch = image_dataset_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images represented as numpy arrays\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 1 = Boats | Class 2 = Planes\n",
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, subplot = plt.subplots(ncols = 4, figsize = (20, 20))\n",
    "for index, image in enumerate(batch[0][:4]):\n",
    "    subplot[index].imshow(image.astype(int))\n",
    "    subplot[index].title.set_text(batch[1][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "# Scaling Data\n",
    "\n",
    "# Cutting down\n",
    "image_dataset = image_dataset.map(lambda x, y: (x / 255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image_dataset_iterator = image_dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e11cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = scaled_image_dataset_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, subplot = plt.subplots(ncols = 4, figsize = (20, 20))\n",
    "for index, image in enumerate(batch[0][:4]):\n",
    "    subplot[index].imshow(image)\n",
    "    subplot[index].title.set_text(batch[1][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d1e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "\n",
    "training_ds_size = int(len(image_dataset) * 0.7)\n",
    "validation_ds_size = int(len(image_dataset) * 0.2) + 1\n",
    "testing_ds_size = int(len(image_dataset) * 0.1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = image_dataset.take(training_ds_size)\n",
    "validation_ds = image_dataset.skip(training_ds_size).take(validation_ds_size)\n",
    "testing_ds = image_dataset.skip(training_ds_size + validation_ds_size).take(testing_ds_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f00dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f056ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "First layer must have an input\n",
    "First layer has 16 filters of 3 by 3 pixels in size with a stride of 1, moving over by\n",
    "    1 pixel each time, these values being called architectural decisions\n",
    "A relu activation takes the output of the convolutional layer and transforms it via a function,\n",
    "    setting all previously negative values to 0 but preserving postive values as is, allowing\n",
    "    for the taking into consideration of non linear patterns\n",
    "\n",
    "'''\n",
    "model.add(Conv2D(16, (3,3), 1, activation = 'relu', input_shape = (256, 256, 3)))\n",
    "\n",
    "'''\n",
    "Takes in the maximum value after the relu activation and returns said value, scanning across the output\n",
    "    and condensing the information over a set region and is not simply returning a singular value\n",
    "'''\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Convolutional Block 2\n",
    "model.add(Conv2D(32, (3,3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Convolutional Block 3\n",
    "model.add(Conv2D(16, (3,3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "'''\n",
    "Flattening the data down\n",
    "When applying convolutional layers, the filters act as the last channel\n",
    "Condense the rows and width and the number of filters form the channel value\n",
    "This is undersired when passing into the dense layer where only a signle value is the goal\n",
    "\n",
    "'''\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layers are fully connected layers\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "When compiling the model, the paramaters passed in include the type of optimizer, the loss, \n",
    "    and the metrics desired to be tracked\n",
    "'''\n",
    "model.compile('adam', loss = tf.losses.BinaryCrossentropy(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b456a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_directory = 'ImageClassifierLogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca104fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_ds, \n",
    "                    epochs = 20, \n",
    "                    validation_data = validation_ds, \n",
    "                    callbacks = [tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b44ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Model Performance\n",
    "\n",
    "# Loss\n",
    "loss_figure = plt.figure()\n",
    "plt.plot(history.history['loss'], color = 'teal', label = 'Loss')\n",
    "plt.plot(history.history['val_loss'], color = 'orange', label = 'Validation Loss')\n",
    "loss_figure.suptitle('Loss', fontsize = 20)\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3da303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_figure = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color = 'teal', label = 'Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color = 'orange', label = 'Validation Accuracy')\n",
    "accuracy_figure.suptitle('Accuracy', fontsize = 20)\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f788c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model Performance\n",
    "\n",
    "model_precision = Precision()\n",
    "model_recall = Recall()\n",
    "model_accuracy = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testing_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in testing_ds.as_numpy_iterator():\n",
    "    x, y = batch\n",
    "    yhat = model.predict(x)\n",
    "    model_precision.update_state(y, yhat)\n",
    "    model_recall.update_state(y, yhat)\n",
    "    model_accuracy.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {model_precision.result().numpy()}')\n",
    "print(f'Recall: {model_recall.result().numpy()}')\n",
    "print(f'Accuracy: {model_accuracy.result().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ee91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing The Model\n",
    "test_image = cv2.imread(os.path.join(image_data_directory, 'Boats', 'TS_Harbor_Sunrise.jpg'))\n",
    "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a837b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_test_image = tf.image.resize(test_image, (256, 256))\n",
    "plt.imshow(resized_test_image.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The model expects a batch of images, not a single individual one, so in order to test this\n",
    "    the image itself must be encapsulated inside another set of parantheses or placed inside\n",
    "    of a list\n",
    "'''\n",
    "test_image_prediction = model.predict(np.expand_dims(resized_test_image / 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b842432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd282273",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(resized_test_image, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resized_test_image / 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aac376",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b19f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(yhat > 0.5):\n",
    "    print('The image is predicted to represent a boat.')\n",
    "else:\n",
    "    print('The image is predicted to represent a plane.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving The Model\n",
    "\n",
    "model.save(os.path.join('models', 'imageClassifierModelBoatPlanes.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b44f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(os.path.join('models', 'imageClassifierModelBoatPlanes.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
